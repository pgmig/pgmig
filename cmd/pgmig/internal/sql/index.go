// Code generated by go-imbed. DO NOT EDIT.

// Package sql holds binary resources embedded into Go executable
package sql

import (
	"os"
	"io"
	"bytes"
	"path/filepath"
	"sort"
	"path"
	"compress/gzip"
	"io/ioutil"
	"time"
)

func blob_bytes(uint32) []byte
func blob_string(uint32) string

// Asset represents binary resource stored within Go executable. Asset implements
// fmt.Stringer and io.WriterTo interfaces, decompressing binary data if necessary.
type Asset struct {
	name         string // File name
	size         int32  // File size (uncompressed)
	blob         []byte // Resource blob []byte
	str_blob     string // Resource blob as string
	isCompressed bool   // true if resources was compressed with gzip
	mime         string // MIME Type
	tag          string // Tag is essentially a Tag of resource content and can be used as a value for "Etag" HTTP header
}

// Name returns the base name of the asset
func (a *Asset) Name() string       { return a.name }
// MimeType returns MIME Type of the asset
func (a *Asset) MimeType() string   { return a.mime }
// IsCompressed returns true of asset has been compressed
func (a *Asset) IsCompressed() bool { return a.isCompressed }
// String returns (uncompressed, if necessary) content of asset as a string
func (a *Asset) String() string {
	if a.isCompressed {
		ungzip, _ := gzip.NewReader(bytes.NewReader(a.blob))
		ret, _ := ioutil.ReadAll(ungzip)
		ungzip.Close()
		return string(ret)
	}
	return a.str_blob
}

// Bytes returns (uncompressed) content of asset as a []byte
func (a *Asset) Bytes() []byte {
	if a.isCompressed {
		ungzip, _ := gzip.NewReader(bytes.NewReader(a.blob))
		ret, _ := ioutil.ReadAll(ungzip)
		ungzip.Close()
		return ret
	}
	ret := make([]byte, len(a.blob))
	copy(ret, a.blob)
	return ret
}

// Size implements os.FileInfo and returns the size of the asset (uncompressed, if asset has been compressed)
func (a *Asset) Size() int64        { return int64(a.size) }
// Mode implements os.FileInfo and always returns 0444
func (a *Asset) Mode() os.FileMode  { return 0444 }
// ModTime implements os.FileInfo and returns the time stamp when this package has been produced (the same value for all the assets)
func (a *Asset) ModTime() time.Time { return stamp }
// IsDir implements os.FileInfo and returns false
func (a *Asset) IsDir() bool        { return false }
// Sys implements os.FileInfo and returns nil
func (a *Asset) Sys() interface{}   { return a }

// WriteTo implements io.WriterTo interface and writes content of the asset to w
func (a *Asset) WriteTo(w io.Writer) (int64, error) {
	if a.isCompressed {
		ungzip, _ := gzip.NewReader(bytes.NewReader(a.blob))
		n, err := io.Copy(w, ungzip)
		ungzip.Close()
		return n, err
	}
	n, err := w.Write(a.blob)
	return int64(n), err
}

type assetReader struct {
	bytes.Reader
}

func (r *assetReader) Close() error {
	r.Reset(nil)
	return nil
}

// Returns content of the asset as io.ReaderCloser.
func (a *Asset) Reader() io.ReadCloser {
	if a.isCompressed {
		ungzip, _ := gzip.NewReader(bytes.NewReader(a.blob))
		return ungzip
	} else {
		ret := &assetReader{}
		ret.Reset(a.blob)
		return ret
	}
}

func cleanPath(path string) string {
	path = filepath.Clean(path)
	if filepath.IsAbs(path) {
		path = path[len(filepath.VolumeName(path)):]
		if len(path) > 0 || os.IsPathSeparator(path[0]) {
			path = path[1:]
		}
	} else if path == "." {
		return ""
	}
	return filepath.ToSlash(path)
}

// Opens asset as an io.ReadCloser. Returns os.ErrNotExist if no asset is found.
func Open(name string) (File, error) {
	return FS().Open(name)
}

// Gets asset by name. Returns nil if no asset found.
func Get(name string) *Asset {
	if entry, ok := fidx[name]; ok {
		return entry
	} else {
		return nil
	}
}

// Get asset by name. Panics if no asset found.
func Must(name string) *Asset {
	if entry, ok := fidx[name]; ok {
		return entry
	} else {
		panic("asset " + name + " not found")
	}
}

type directoryAsset struct {
	name  string
	dirs  []directoryAsset
	files []Asset
}

var root *directoryAsset

// A simple FileSystem abstraction
type FileSystem interface {
	Open(name string) (File, error)
	Stat(name string) (os.FileInfo, error)
	// As in filepath.Walk
	Walk(root string, walkFunc filepath.WalkFunc) error
}

// The CopyTo method extracts all mentioned files
// to a specified location, keeping directory structure.
// If supplied file is a directory, than it will be extracted
// recursively. CopyTo with no file mentioned will extract
// the whole content of the embedded filesystem.
// CopyTo returns error if there is a file with the same name
// at the target location, unless overwrite is set to true, or
// file has the same size and modification file as the extracted
// file.
// sql.CopyTo(".", mode, false) will effectively
// extract content of the filesystem to the current directory (which
// makes it the most space-wise inefficient self-extracting archive
// ever).
func CopyTo(target string, mode os.FileMode, overwrite bool, files ...string) error {
	mode    =  mode&0777
	dirmode := os.ModeDir|((mode&0444)>>2)|mode
	if len(files) == 0 {
		files = []string{""}
	}
	for _, file := range files {
		file = cleanPath(file)
		err := FS().Walk(file, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return err
			}
			targetPath := filepath.Join(target, path)
			fi, err := os.Stat(targetPath)
			if err == nil {
				if info.IsDir() && fi.IsDir() {
					return nil
				} else if info.IsDir() != fi.IsDir() {
					return os.ErrExist
				} else if !overwrite {
					if info.Size() == fi.Size() && info.ModTime().Equal(fi.ModTime()) {
						return nil
					} else {
						return os.ErrExist
					}
				}
			}
			if info.IsDir() {
				return os.MkdirAll(targetPath, dirmode)
			}
			asset := Get(path)
			if asset == nil {
				return os.ErrNotExist
			}
			targetPathDir := filepath.Dir(targetPath)
			if err = os.MkdirAll(targetPathDir, dirmode); err != nil {
				return err
			}
			dst, err := ioutil.TempFile(targetPathDir, ".imbed")
			if err != nil {
				return err
			}
			defer func() {
				dst.Close()
				os.Remove(dst.Name())
			}()
			_, err = asset.WriteTo(dst)
			if err != nil {
				return err
			}
			dst.Close()
			os.Chtimes(dst.Name(), info.ModTime(), info.ModTime())
			os.Chmod(dst.Name(), mode)
			return os.Rename(dst.Name(), targetPath)
		})
		if err != nil {
			return err
		}
	}
	return nil
}

type fileInfoSlice []os.FileInfo
func (fis *fileInfoSlice) Len() int           { return len(*fis) }
func (fis *fileInfoSlice) Less(i, j int) bool { return (*fis)[i].Name() < (*fis)[j].Name() }
func (fis *fileInfoSlice) Swap(i, j int) {
	s := (*fis)[i]
	(*fis)[i] = (*fis)[j]
	(*fis)[j] = s
}

func walkRec(fs FileSystem, info os.FileInfo, p string, walkFn filepath.WalkFunc) error {
	var (
		dir File
		fis fileInfoSlice
		err error
	)
	err = walkFn(p, info, nil)
	if err != nil {
		if info.IsDir() && err == filepath.SkipDir {
			return nil
		}
		return err
	}
	if !info.IsDir() {
		return nil
	}
	dir, err = fs.Open(p)
	if err != nil {
		return walkFn(p, info, err)
	}
	fis, err = dir.Readdir(-1)
	if err != nil {
		return walkFn(p, info, err)
	}
	sort.Sort(&fis)
	for i := range fis {
		fn := path.Join(p, fis[i].Name())
		err = walkRec(fs, fis[i], fn, walkFn)
		if err != nil {
			if !fis[i].IsDir() || err != filepath.SkipDir {
				return err
			}
		}
	}
	return nil
}

func walk(fs FileSystem, name string, walkFunc filepath.WalkFunc) error {
	var r os.FileInfo
	var err error
	name = cleanPath(name)
	r, err = fs.Stat(name)
	if err != nil {
		return err
	}
	return walkRec(fs, r, name, walkFunc)
}

type assetFs struct{}

// Returns embedded FileSystem
func FS() FileSystem {
	return &assetFs{}
}

func (fs *assetFs) Walk(root string, walkFunc filepath.WalkFunc) error {
	return walk(fs, root, walkFunc)
}

func (fs *assetFs) Stat(name string) (os.FileInfo, error) {
	name = cleanPath(name)
	if name == "" {
		return root, nil
	}
	if dir, ok := didx[name]; ok {
		return dir, nil
	}
	if asset, ok := fidx[name]; ok {
		return asset, nil
	}
	return nil, os.ErrNotExist
}

func (fs *assetFs) Open(name string) (File, error) {
	name = cleanPath(name)
	if name == "" {
		return root.open(""), nil
	}
	if dir, ok := didx[name]; ok {
		return dir.open(name), nil
	}
	if asset, ok := fidx[name]; ok {
		return asset.open(name), nil
	}
	return nil, os.ErrNotExist
}


// A File is returned by virtual FileSystem's Open method.
// The methods should behave the same as those on an *os.File.
type File interface {
	io.Closer
	io.Reader
	io.Seeker
	Readdir(count int) ([]os.FileInfo, error)
	Stat() (os.FileInfo, error)
}

func (a *Asset) open(name string) File {
	if a.isCompressed {
		ret := &assetCompressedFile{
			asset: a,
			name:  name,
		}
		ret.Reset(bytes.NewReader(a.blob))
		return ret
	} else {
		ret := &assetFile{
			asset: a,
			name:  name,
		}
		ret.Reset(a.blob)
		return ret
	}
}

func (d *directoryAsset) open(name string) File {
	return &directoryAssetFile{
		dir:  d,
		name: name,
		pos:  0,
	}
}

type directoryAssetFile struct {
	dir  *directoryAsset
	name string
	pos  int
}

func (d *directoryAssetFile) Name() string {
	return d.name
}

func (d *directoryAssetFile) checkClosed() error {
	if d.pos < 0 {
		return os.ErrClosed
	}
	return nil
}

func (d *directoryAssetFile) Close() error {
	if err := d.checkClosed(); err != nil {
		return err
	}
	d.pos = -1
	return nil
}

func (d *directoryAssetFile) Read([]byte) (int, error) {
	if err := d.checkClosed(); err != nil {
		return 0, err
	}
	return 0, io.EOF
}

func (d *directoryAssetFile) Stat() (os.FileInfo, error) {
	if err := d.checkClosed(); err != nil {
		return nil, err
	}
	return d.dir, nil
}

func (d *directoryAssetFile) Seek(pos int64, whence int) (int64, error) {
	if err := d.checkClosed(); err != nil {
		return 0, err
	}
	return 0, os.ErrInvalid
}

func (d *directoryAssetFile) Readdir(count int) ([]os.FileInfo, error) {
	if err := d.checkClosed(); err != nil {
		return nil, err
	}
	var (
		last int
		total = len(d.dir.dirs) + len(d.dir.files)
	)
	if d.pos > total {
		if count > 0 {
			return nil, io.EOF
		} else {
			return nil, nil
		}
	}
	if count <= 0 || (d.pos + count) <= total {
		last = total
	} else {
		last = d.pos + count
	}
	ret := make([]os.FileInfo, 0, last - d.pos)
	if d.pos < len(d.dir.dirs) {
		var stop int
		if last > len(d.dir.dirs) {
			stop = len(d.dir.dirs)
		} else {
			stop = last
		}
		for i := d.pos; i < stop; i++ {
			ret = append(ret, &d.dir.dirs[i])
		}
		d.pos = stop
	}
	var start, stop int
	start = d.pos - len(d.dir.dirs)
	stop = last - len(d.dir.dirs)
	for i := start; i < stop; i++ {
		ret = append(ret, &d.dir.files[i])
	}
	d.pos = last
	return ret, nil
}

func (d *directoryAsset) Name() string       { return d.name }
func (d *directoryAsset) Size() int64        { return 0 }
func (d *directoryAsset) Mode() os.FileMode  { return os.ModeDir | 0555 }
func (d *directoryAsset) ModTime() time.Time { return stamp }
func (d *directoryAsset) IsDir() bool        { return true }
func (d *directoryAsset) Sys() interface{}   { return d }

type assetFile struct {
	assetReader
	name string
	asset *Asset
}

func (a *assetFile) Name() string {
	return a.name
}

func (a *assetFile) Stat() (os.FileInfo, error) {
	return a.asset, nil
}

func (a *assetFile) Readdir(int) ([]os.FileInfo, error) {
	return nil, os.ErrInvalid
}
type assetCompressedFile struct {
	gzip.Reader
	name  string
	asset *Asset
}

func (a *assetCompressedFile) Name() string {
	return a.name
}

func (a *assetCompressedFile) Stat() (os.FileInfo, error) {
	return a.asset, nil
}

func (a *assetCompressedFile) Seek(int64, int) (int64, error) {
	return 0, os.ErrInvalid
}

func (a *assetCompressedFile) Readdir(count int) ([]os.FileInfo, error) {
	return nil, os.ErrInvalid
}

type unionFs struct {
	root string
}

func NewUnionFS(src string) (FileSystem, error) {
	abs, err := filepath.Abs(src)
	if err != nil {
		return nil, err
	}
	return &unionFs{
		root: abs,
	}, nil
}

func (fs *unionFs) Stat(name string) (os.FileInfo, error) {
	name = cleanPath(name)
	fname := filepath.Join(fs.root, filepath.FromSlash(name))
	fi, err := os.Stat(fname)
	if err == nil {
		return fi, nil
	}
	return FS().Stat(name)
}

func (fs *unionFs) Open(name string) (File, error) {
	name = cleanPath(name)
	fname := filepath.Join(fs.root, filepath.FromSlash(name))
	fi, err := os.Stat(fname)
	if err == nil {
		file, err := os.OpenFile(fname, os.O_RDONLY, 0)
		if err == nil {
			if !fi.IsDir() {
				return &unionFsFile{
					name: name,
					file: file,
				}, nil
			} else {
				dir, _ := didx[name]
				return &unionFsDirectoryFile{
					name:  name,
					dir:   dir,
					fsDir: file,
					pos:   0,
				}, nil
			}
		}
	}
	return FS().Open(name)
}

func (fs *unionFs) Walk(root string, walkFunc filepath.WalkFunc) error {
	return walk(fs, root, walkFunc)
}

type unionFsFile struct {
	name string
	file *os.File
}

func (f *unionFsFile) Name() string { return f.name }
func (f *unionFsFile) Close() error { return f.file.Close() }
func (f *unionFsFile) Read(d []byte) (int, error) { return f.file.Read(d) }
func (f *unionFsFile) Stat() (os.FileInfo, error) { return f.file.Stat() }
func (f *unionFsFile) Seek(pos int64, whence int) (int64, error) { return f.file.Seek(pos, whence) }
func (f *unionFsFile) Readdir(count int) ([]os.FileInfo, error) { return f.file.Readdir(count) }

type unionFsDirectoryFile struct {
	name  string
	dir   *directoryAsset
	fsDir *os.File
	pos   int
}

func (d *unionFsDirectoryFile) Name() string { return d.name }
func (d *unionFsDirectoryFile) Close() error {
	if d.fsDir == nil {
		return os.ErrClosed
	}
	err := d.fsDir.Close()
	d.fsDir = nil
	return err
}

func (d *unionFsDirectoryFile) Read([]byte) (int, error) {
	if d.fsDir == nil {
		return 0, os.ErrClosed
	}
	return 0, io.EOF
}

func (d *unionFsDirectoryFile) Stat() (os.FileInfo, error) {
	if d.fsDir == nil {
		return nil, os.ErrClosed
	}
	return d.fsDir.Stat()
}

func (d *unionFsDirectoryFile) Seek(pos int64, whence int) (int64, error) {
	if d.fsDir == nil {
		return 0, os.ErrClosed
	}
	return 0, os.ErrInvalid
}
func (d *unionFsDirectoryFile) Readdir(count int) ([]os.FileInfo, error) {
	if d.fsDir == nil {
		return nil, os.ErrClosed
	}
	if d.pos < 0 {
		if count > 0 {
			return nil, io.EOF
		} else {
			return nil, nil
		}
	}
	if d.dir == nil {
		return d.fsDir.Readdir(count)
	}
	ret, err := d.fsDir.Readdir(count)
	if count > 0 && err == nil {
		return ret, err
	}
	embedded := make([]os.FileInfo, 0, len(d.dir.dirs) + len(d.dir.files))
	for i := range d.dir.dirs {
		embedded = append(embedded, &d.dir.dirs[i])
	}
	for i := range d.dir.files {
		embedded = append(embedded, &d.dir.files[i])
	}
	for _, fi := range embedded[d.pos:] {
		if count > 0 && len(ret) >= count {
			return ret, nil
		}
		d.pos++
		if _, err := os.Stat(filepath.Join(d.fsDir.Name(), fi.Name())); err == nil {
			continue
		}
		ret = append(ret, fi)
	}
	d.pos = -1
	return ret, nil
}

var fidx = make(map[string]*Asset)
var didx = make(map[string]*directoryAsset)
var stamp time.Time

func init() {
	stamp = time.Unix(1679388140, 761452665)
	bb := blob_bytes(48744)
	bs := blob_string(48744)
	root = &directoryAsset{
		dirs: []directoryAsset{
			{
				name: "pgmig",
				files: []Asset{
					{
						name:         ".git",
						blob:         bb[0:37],
						str_blob:     bs[0:37],
						mime:         "application/binary",
						tag:          "dilmbvavwp76o",
						size:         37,
						isCompressed: false,
					},
					{
						name:         ".gitignore",
						blob:         bb[40:103],
						str_blob:     bs[40:103],
						mime:         "application/binary",
						tag:          "vapqilfgxpmdk",
						size:         63,
						isCompressed: false,
					},
					{
						name:         "00_schema.new.sql",
						blob:         bb[104:564],
						str_blob:     bs[104:564],
						mime:         "application/x-sql",
						tag:          "acb6vu53iyyww",
						size:         460,
						isCompressed: false,
					},
					{
						name:         "17_comment.sql",
						blob:         bb[568:5891],
						str_blob:     bs[568:5891],
						mime:         "application/x-sql",
						tag:          "bykegi7bzx7tw",
						size:         5323,
						isCompressed: false,
					},
					{
						name:         "18_assert.sql",
						blob:         bb[5896:7502],
						str_blob:     bs[5896:7502],
						mime:         "application/x-sql",
						tag:          "oqk2mtxnxqhxw",
						size:         1606,
						isCompressed: false,
					},
					{
						name:         "18_assert.test.sql",
						blob:         bb[7504:7906],
						str_blob:     bs[7504:7906],
						mime:         "application/x-sql",
						tag:          "h6xftflbpz2tc",
						size:         402,
						isCompressed: false,
					},
					{
						name:         "19_comment.test.sql",
						blob:         bb[7912:15665],
						str_blob:     bs[7912:15665],
						mime:         "application/x-sql",
						tag:          "oavqmuc5djhak",
						size:         7753,
						isCompressed: false,
					},
					{
						name:         "19_exists.sql",
						blob:         bb[15672:16242],
						str_blob:     bs[15672:16242],
						mime:         "application/x-sql",
						tag:          "a75tfo34izxkg",
						size:         570,
						isCompressed: false,
					},
					{
						name:         "19_search.sql",
						blob:         bb[16248:16570],
						str_blob:     bs[16248:16570],
						mime:         "application/x-sql",
						tag:          "w5k7x5oxui4mo",
						size:         322,
						isCompressed: false,
					},
					{
						name:         "19_t_op.new.sql",
						blob:         bb[16576:16668],
						str_blob:     bs[16576:16668],
						mime:         "application/x-sql",
						tag:          "tracenhooie5m",
						size:         92,
						isCompressed: false,
					},
					{
						name:         "20_pers.new.sql",
						blob:         bb[16672:17087],
						str_blob:     bs[16672:17087],
						mime:         "application/x-sql",
						tag:          "wizja7mydat4u",
						size:         415,
						isCompressed: false,
					},
					{
						name:         "20_pkg.sql",
						blob:         bb[17088:19114],
						str_blob:     bs[17088:19114],
						mime:         "application/x-sql",
						tag:          "5vyc634d2hlqo",
						size:         2026,
						isCompressed: false,
					},
					{
						name:         "20_protected.sql",
						blob:         bb[19120:21030],
						str_blob:     bs[19120:21030],
						mime:         "application/x-sql",
						tag:          "vzh4xrxeufcna",
						size:         1910,
						isCompressed: false,
					},
					{
						name:         "50_cleanup.sql",
						blob:         bb[21032:21336],
						str_blob:     bs[21032:21336],
						mime:         "application/x-sql",
						tag:          "corvzmk5htz3q",
						size:         304,
						isCompressed: false,
					},
					{
						name:         "50_pkg.sql",
						blob:         bb[21336:33838],
						str_blob:     bs[21336:33838],
						mime:         "application/x-sql",
						tag:          "42yqtwwvevzaw",
						size:         12502,
						isCompressed: false,
					},
					{
						name:         "50_pkg.test.sql",
						blob:         bb[33840:36100],
						str_blob:     bs[33840:36100],
						mime:         "application/x-sql",
						tag:          "q3tu3yyax2gce",
						size:         2260,
						isCompressed: false,
					},
					{
						name:         "50_var.sql",
						blob:         bb[36104:36517],
						str_blob:     bs[36104:36517],
						mime:         "application/x-sql",
						tag:          "if47lzfgehgbq",
						size:         413,
						isCompressed: false,
					},
					{
						name:         "60_grant.sql",
						blob:         bb[36520:36859],
						str_blob:     bs[36520:36859],
						mime:         "application/x-sql",
						tag:          "e3q423trwynzc",
						size:         339,
						isCompressed: false,
					},
					{
						name:         "79_assert_fail.sql",
						blob:         bb[36864:37012],
						str_blob:     bs[36864:37012],
						mime:         "application/x-sql",
						tag:          "7gxloirxbhma4",
						size:         148,
						isCompressed: false,
					},
					{
						name:         "LICENSE",
						blob:         bb[37016:48373],
						str_blob:     bs[37016:48373],
						mime:         "application/binary",
						tag:          "5x6p4joesftny",
						size:         11357,
						isCompressed: false,
					},
					{
						name:         "README.md",
						blob:         bb[48376:48594],
						str_blob:     bs[48376:48594],
						mime:         "text/markdown; charset=utf-8",
						tag:          "xtwrtrueicvu6",
						size:         311,
						isCompressed: true,
					},
					{
						name:         "gitinfo.json",
						blob:         bb[48600:48737],
						str_blob:     bs[48600:48737],
						mime:         "application/json",
						tag:          "juh5g336zarcw",
						size:         137,
						isCompressed: false,
					},
				},
			},
		},
	}
	didx[""] = root
	didx["pgmig"] = &root.dirs[0]
	fidx["pgmig/.git"] = &root.dirs[0].files[0]
	fidx["pgmig/.gitignore"] = &root.dirs[0].files[1]
	fidx["pgmig/00_schema.new.sql"] = &root.dirs[0].files[2]
	fidx["pgmig/17_comment.sql"] = &root.dirs[0].files[3]
	fidx["pgmig/18_assert.sql"] = &root.dirs[0].files[4]
	fidx["pgmig/18_assert.test.sql"] = &root.dirs[0].files[5]
	fidx["pgmig/19_comment.test.sql"] = &root.dirs[0].files[6]
	fidx["pgmig/19_exists.sql"] = &root.dirs[0].files[7]
	fidx["pgmig/19_search.sql"] = &root.dirs[0].files[8]
	fidx["pgmig/19_t_op.new.sql"] = &root.dirs[0].files[9]
	fidx["pgmig/20_pers.new.sql"] = &root.dirs[0].files[10]
	fidx["pgmig/20_pkg.sql"] = &root.dirs[0].files[11]
	fidx["pgmig/20_protected.sql"] = &root.dirs[0].files[12]
	fidx["pgmig/50_cleanup.sql"] = &root.dirs[0].files[13]
	fidx["pgmig/50_pkg.sql"] = &root.dirs[0].files[14]
	fidx["pgmig/50_pkg.test.sql"] = &root.dirs[0].files[15]
	fidx["pgmig/50_var.sql"] = &root.dirs[0].files[16]
	fidx["pgmig/60_grant.sql"] = &root.dirs[0].files[17]
	fidx["pgmig/79_assert_fail.sql"] = &root.dirs[0].files[18]
	fidx["pgmig/LICENSE"] = &root.dirs[0].files[19]
	fidx["pgmig/README.md"] = &root.dirs[0].files[20]
	fidx["pgmig/gitinfo.json"] = &root.dirs[0].files[21]
}
